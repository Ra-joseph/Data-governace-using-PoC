# Data Governance Platform

A comprehensive Policy-as-Code data governance platform implementing federated governance using the UN Peacekeeping model. This platform features a **multi-role React frontend** with dedicated UIs for Data Owners, Data Consumers, Data Stewards, and Platform Admins, enabling complete end-to-end data governance workflows.

## ğŸ¯ Key Features

### Core Platform
- **Federated Governance**: UN Peacekeeping model â€” shared policies with distributed enforcement
- **Policy-as-Code**: 17 YAML-defined governance policies with automated validation
- **Semantic Policy Scanning**: 8 LLM-powered policies via local Ollama (privacy-first)
- **Intelligent Orchestration**: FAST/BALANCED/THOROUGH/ADAPTIVE validation strategies
- **Automated Schema Import**: PostgreSQL with heuristic PII detection
- **Dual Contracts**: Human-readable YAML + Machine-readable JSON (SHA-256 schema hashing)
- **Git Version Control**: All contracts tracked with semantic versioning and full audit trail
- **Prevention at Borders**: Catch violations before publication, not after cascade
- **Actionable Remediation**: Every violation includes step-by-step "how to fix it" guidance

### Multi-Role Frontend
- **Data Owner UI**: Multi-step dataset registration wizard, violation dashboard, subscriber tracking
- **Data Consumer UI**: Catalog browser with search/filter, subscription requests with SLA negotiation
- **Data Steward UI**: Approval queue, contract review, access credential management
- **Platform Admin UI**: Compliance metrics, violation trends, Recharts analytics dashboards
- **End-to-End Workflows**: Complete subscription lifecycle with automatic contract versioning

## ğŸ“‹ Table of Contents

- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Multi-Role Frontend](#multi-role-frontend)
- [End-to-End Workflows](#end-to-end-workflows)
- [API Documentation](#api-documentation)
- [Demo Scenario](#demo-scenario)
- [Policy Definitions](#policy-definitions)
- [Troubleshooting](#troubleshooting)
- [Next Steps](#next-steps)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Frontend Layer (React 18 + Vite, port 5173)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Owner  â”‚ Data Consumerâ”‚ Data Steward â”‚  Platform Admin     â”‚
â”‚      UI      â”‚      UI      â”‚      UI      â”‚       UI            â”‚
â”‚  â€¢ Register  â”‚  â€¢ Browse    â”‚  â€¢ Approve   â”‚  â€¢ Metrics          â”‚
â”‚  â€¢ Manage    â”‚  â€¢ Subscribe â”‚  â€¢ Review    â”‚  â€¢ Trends           â”‚
â”‚  â€¢ Violationsâ”‚  â€¢ Request   â”‚  â€¢ Credentialsâ”‚ â€¢ Analytics        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–²
                                 â”‚ REST API (Axios / Vite proxy)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FastAPI Backend (Python 3.10+, port 8000)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Dataset    â”‚  â”‚   Contract   â”‚  â”‚ Subscription â”‚          â”‚
â”‚  â”‚   Registry   â”‚â—„â”€â”¤  Management  â”‚â—„â”€â”¤   Workflow   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                  â”‚                  â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                            â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Policy Orchestrator (Intelligent Routing)        â”‚   â”‚
â”‚  â”‚  FAST â”€â”€â–º Rule Engine     THOROUGH â”€â”€â–º Rule + Semantic   â”‚   â”‚
â”‚  â”‚  ADAPTIVE â”€â”€â–º Auto-selects based on risk analysis         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â–¼                                           â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Rule-Based Policy Engineâ”‚  â”‚ Semantic Policy Engine    â”‚     â”‚
â”‚  â”‚ (17 YAML policies)      â”‚  â”‚ (8 LLM policies, Ollama)  â”‚     â”‚
â”‚  â”‚ SD001-SD005 sensitive   â”‚  â”‚ SEM001-SEM008 context     â”‚     â”‚
â”‚  â”‚ DQ001-DQ005 quality     â”‚  â”‚ Business logic validation â”‚     â”‚
â”‚  â”‚ SG001-SG007 schema      â”‚  â”‚ Security pattern detect   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚              Git Repository (Contracts)            â”‚          â”‚
â”‚  â”‚  â€¢ Semantic versioning  â€¢ Full audit trail         â”‚          â”‚
â”‚  â”‚  â€¢ Diff/compare         â€¢ SHA-256 schema hash      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Storage Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  SQLite DB   â”‚  â”‚ PostgreSQL   â”‚  â”‚  Git Repo    â”‚          â”‚
â”‚  â”‚  (metadata)  â”‚  â”‚  (demo data) â”‚  â”‚  (contracts) â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Data Sources                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚PostgreSQLâ”‚  â”‚  Files   â”‚  â”‚Azure Blobâ”‚  â”‚ Azure DL â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

**Backend Services:**
1. **Dataset Registry**: SQLAlchemy catalog of all data assets with metadata and lifecycle status
2. **Contract Management**: Dual-format YAML+JSON contracts with SHA-256 schema hashing and semantic versioning
3. **Rule-Based Policy Engine**: Validates contracts against 17 YAML-defined governance policies
4. **Semantic Policy Engine**: LLM-powered validation with 8 context-aware policies via local Ollama
5. **Policy Orchestrator**: Intelligent routing â€” selects FAST/BALANCED/THOROUGH/ADAPTIVE strategy based on risk assessment
6. **PostgreSQL Connector**: Schema import with heuristic PII detection (email, SSN, phone, DOB patterns)
7. **Git Service**: Contract version control, audit trail, diffs, and commit history
8. **Subscription API**: Complete approval workflow with access credential generation

**Frontend (React 18 + Vite):**
1. **Role-Based UIs**: Dedicated interfaces for Owner, Consumer, Steward, and Admin roles
2. **Dataset Registration Wizard**: 4-step form (info â†’ schema â†’ governance â†’ review) with real-time validation
3. **Catalog Browser**: Grid view with search, filter by classification, and subscription requests
4. **Approval Queue**: Review business justification, select approved fields, generate credentials
5. **Compliance Dashboard**: Real-time metrics and interactive Recharts visualizations

## ğŸ“¦ Prerequisites

- **Python**: 3.10 or higher
- **Node.js**: 18 or higher (for frontend)
- **npm**: 9 or higher (comes with Node.js)
- **Docker**: For PostgreSQL demo database
- **Git**: For contract version control

## ğŸš€ Installation

### Step 1: Clone or Download (2 minutes)

If you received this as a zip file, extract it. Otherwise:

```bash
git clone <repository-url>
cd data-governance-platform
```

### Step 2: Setup Python Environment (2 minutes)

```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
# On macOS/Linux:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# Install dependencies
cd backend
pip install -r requirements.txt
cd ..
```

### Step 3: Start PostgreSQL Demo Database (1 minute)

```bash
# Start PostgreSQL with demo data
docker-compose up -d

# Verify PostgreSQL is running
docker ps

# You should see: governance_postgres container running on port 5432
```

### Step 4: Setup Frontend (2 minutes)

```bash
# Install frontend dependencies
cd frontend
npm install
cd ..
```

### Step 5: Start Backend API (1 minute)

```bash
# Option 1: Using the start script
chmod +x start.sh
./start.sh

# Option 2: Manual start
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at: http://localhost:8000

### Step 6: Start Frontend (1 minute)

```bash
# In a new terminal
cd frontend
npm run dev
```

The frontend will be available at: http://localhost:5173

### Step 7: Verify Installation (1 minute)

```bash
# In a new terminal, run the test suite
python test_setup.py
```

You should see:
- âœ“ Health Check
- âœ“ PostgreSQL Connection
- âœ“ Schema Import
- âœ“ Dataset Registration
- âœ“ List Datasets

## ğŸ¬ Quick Start

### Option 1: Using the Frontend (Recommended)

1. **Access the application** at http://localhost:5173/select-role

2. **Select "Data Owner"** to register a dataset
   - Click on the Data Owner card
   - Navigate to "Register Dataset"
   - Click "Import from PostgreSQL" in Step 2
   - Select `customer_accounts` table
   - Complete the wizard and submit
   - View the validation results

3. **Select "Data Consumer"** to browse and subscribe
   - Return to http://localhost:5173/select-role
   - Click on the Data Consumer card
   - Browse the catalog
   - Click "Request Access" on a dataset
   - Fill in business justification and SLA requirements
   - Submit subscription request

4. **Select "Data Steward"** to approve requests
   - Return to http://localhost:5173/select-role
   - Click on the Data Steward card
   - View the pending subscription in the approval queue
   - Click "Review"
   - Approve with credentials or reject with notes

5. **Select "Platform Admin"** to view metrics
   - Return to http://localhost:5173/select-role
   - Click on the Platform Admin card
   - View compliance dashboard with charts and metrics

### Option 2: Using the API

### Import Schema from PostgreSQL

```bash
curl -X POST http://localhost:8000/api/v1/datasets/import-schema \
  -H "Content-Type: application/json" \
  -d '{
    "source_type": "postgres",
    "table_name": "customer_accounts",
    "schema_name": "public"
  }'
```

**Expected Response:**
```json
{
  "table_name": "customer_accounts",
  "schema_name": "public",
  "description": "Customer account information - CONTAINS PII",
  "schema_definition": [...],
  "metadata": {
    "contains_pii": true,
    "suggested_classification": "confidential",
    "primary_keys": ["account_id"],
    "row_count": 10
  }
}
```

### Register Dataset

```bash
curl -X POST http://localhost:8000/api/v1/datasets/ \
  -H "Content-Type: application/json" \
  -d @examples/register_customer_accounts.json
```

**What Happens:**
1. Dataset is created in the registry
2. Initial contract (v1.0.0) is generated
3. Contract is validated against all policies
4. Contract is committed to Git repository
5. Violations are reported with remediation guidance

### View Generated Contract

```bash
# Check the Git repository
ls -la backend/contracts/

# View the contract
cat backend/contracts/customer_accounts_v1.0.0.yaml
```

**Example Contract:**
```yaml
# Data Contract
# Dataset: customer_accounts
# Version: 1.0.0
# Generated: 2024-02-04 15:30:00

dataset:
  name: customer_accounts
  owner_name: John Doe
  owner_email: john.doe@company.com
  version: 1.0.0

schema:
  - name: customer_ssn
    type: string
    pii: true
    description: Social Security Number - SENSITIVE DATA
    max_length: 11

governance:
  classification: confidential
  encryption_required: true
  retention_days: 2555
  compliance_tags:
    - GDPR
    - CCPA
```

## ğŸ¨ Multi-Role Frontend

The platform features a complete React-based frontend with dedicated UIs for each role in the data governance workflow.

### Accessing the Frontend

1. Start both backend and frontend (see Installation)
2. Navigate to http://localhost:5173/select-role
3. Select your role to access the corresponding UI

### Role-Based User Interfaces

#### ğŸ—‚ï¸ Data Owner UI

**Dashboard** (`/owner/dashboard`)
- View all owned datasets with status and violations
- Track subscriber counts and activity
- Get actionable remediation for policy violations
- Quick access to register new datasets

**Dataset Registration Wizard** (`/owner/register`)
- **Step 1 - Basic Info**: Name, description, owner details
- **Step 2 - Schema**: Manual entry or PostgreSQL import
- **Step 3 - Governance**: Classification, retention, compliance tags
- **Step 4 - Review**: Final review before submission
- **Auto-validation**: Immediate policy check on submission
- **PII Detection**: Automatic detection of sensitive fields

**Features:**
- Real-time violation alerts with remediation guidance
- PostgreSQL schema import with automatic PII detection
- Multi-step wizard with validation at each step
- Dataset status tracking (draft, published, deprecated)

#### ğŸ›’ Data Consumer UI

**Catalog Browser** (`/consumer/catalog`)
- Browse all published datasets
- Search by name or description
- Filter by classification level
- View dataset details and schema
- See compliance status and tags

**Subscription Request Form**
- Business justification field
- Use case specification
- SLA requirements:
  - Max latency (ms)
  - Min availability (%)
  - Max staleness (minutes)
- Field-level access selection
- Access duration configuration

**Features:**
- Grid view with dataset cards
- Real-time search and filtering
- Detailed schema preview
- Compliance badge display

#### âš–ï¸ Data Steward UI

**Approval Queue** (`/steward/approvals`)
- View pending, approved, and rejected subscriptions
- Filter by status
- Detailed request information
- Use case and justification review

**Review Modal**
- Approve or reject with notes
- Select approved fields (subset of requested)
- Generate access credentials:
  - Username
  - API key
  - Connection string (optional)
- Add reviewer comments

**Features:**
- Automatic contract versioning on approval
- Access credential generation
- Comprehensive request details
- Subscription history tracking

#### ğŸ“Š Platform Admin UI

**Compliance Dashboard** (`/admin/dashboard`)

**Key Metrics:**
- Compliance rate with trend
- Total active violations
- Active subscriptions
- Pending approvals

**Analytics Charts:**
- **Violation Trends**: Line chart showing violations over time
- **Violations by Severity**: Pie chart (critical, warning, info)
- **Top Violated Policies**: Bar chart of most common violations
- **Compliance by Classification**: Stacked bar chart by data class

**Recent Activity:**
- Latest policy violations
- New subscription requests
- Dataset registrations

**Features:**
- Real-time metrics
- Interactive Recharts visualizations
- Drill-down capabilities
- Export-ready data

## ğŸ”„ End-to-End Workflows

### Workflow 1: Dataset Registration

```
Data Owner Actions:
1. Navigate to /owner/register
2. Enter dataset information (3-step wizard)
3. Import schema from PostgreSQL or enter manually
4. Set governance rules and compliance tags
5. Review and submit

System Actions:
1. Create dataset in registry
2. Generate data contract (v1.0.0)
3. Validate against 17 policies
4. Commit contract to Git
5. Return validation report with violations

Data Owner Result:
- Dataset published (if compliant) or draft (if violations)
- View violations with remediation on dashboard
- Track dataset in owner dashboard
```

### Workflow 2: Data Subscription

```
Data Consumer Actions:
1. Browse catalog (/consumer/catalog)
2. Select dataset
3. Click "Request Access"
4. Fill subscription form:
   - Business justification
   - Use case
   - SLA requirements
   - Select needed fields
5. Submit request

System Actions:
1. Create subscription record (status: pending)
2. Notify data steward (future: email/webhook)
3. Queue request in approval system

Data Steward Actions:
1. View request in /steward/approvals
2. Review business justification and use case
3. Verify SLA feasibility
4. Approve or reject with notes
5. Generate access credentials (if approved)

System Actions (on approval):
1. Update subscription status to "approved"
2. Store access credentials
3. Create new contract version (v1.1.0)
4. Add subscription SLA to contract
5. Commit new contract to Git
6. Grant access to consumer

Data Consumer Result:
- Receive access credentials
- Can access approved fields
- SLA enforced by platform
```

### Workflow 3: Violation Remediation

```
Data Owner Actions:
1. View violation alert on /owner/dashboard
2. Click violation to see details
3. Read remediation guidance
4. Fix issue in source or update metadata
5. Re-submit or update dataset

System Actions:
1. Re-validate contract
2. Update validation status
3. Commit new contract version if changed
4. Clear violation if resolved

Data Owner Result:
- Dataset moves from draft to published
- Violation removed from dashboard
- Compliance metrics updated
```

### Workflow 4: Compliance Monitoring

```
Platform Admin Actions:
1. View /admin/dashboard daily
2. Review compliance rate trend
3. Identify top violated policies
4. Drill into specific violations
5. Report to stakeholders

System Actions:
1. Aggregate metrics across all datasets
2. Calculate trends over time
3. Generate violation analytics
4. Update charts in real-time

Platform Admin Result:
- Understand platform health
- Identify systemic issues
- Track improvement over time
- Data-driven governance decisions
```

## ğŸ“š API Documentation

### Interactive Documentation

Visit http://localhost:8000/api/docs for Swagger UI with interactive API testing.

### Core Endpoints

**Base URL:** `http://localhost:8000/api/v1`

#### Datasets

- `POST /api/v1/datasets/` - Register new dataset (triggers contract generation + policy validation)
- `GET /api/v1/datasets/` - List datasets (filters: `skip`, `limit`, `status`, `classification`)
- `GET /api/v1/datasets/{id}` - Get dataset details with contracts and violations
- `PUT /api/v1/datasets/{id}` - Update dataset (triggers re-validation)
- `DELETE /api/v1/datasets/{id}` - Soft delete dataset

#### Schema Import

- `POST /api/v1/datasets/import-schema` - Import schema from PostgreSQL or file (returns PII detection)
- `GET /api/v1/datasets/postgres/tables` - List available PostgreSQL tables

#### Subscriptions

- `POST /api/v1/subscriptions/` - Create subscription request (status: pending)
- `GET /api/v1/subscriptions/` - List subscriptions (filters: `status`, `dataset_id`, `consumer_email`)
- `GET /api/v1/subscriptions/{id}` - Get subscription details
- `POST /api/v1/subscriptions/{id}/approve` - Approve or reject (generates credentials + new contract version)
- `PUT /api/v1/subscriptions/{id}` - Update subscription
- `DELETE /api/v1/subscriptions/{id}` - Cancel subscription

#### Git

- `GET /api/v1/git/commits` - List contract commits with metadata
- `GET /api/v1/git/commits/{hash}` - Get commit details and diff
- `GET /api/v1/git/diff/{old}..{new}` - Compare contract versions (unified diff)
- `GET /api/v1/git/contracts` - List all contract files
- `POST /api/v1/git/tag` - Create version tag

#### Semantic Policy Validation

- `GET /api/v1/semantic/health` - Ollama status and available models
- `GET /api/v1/semantic/policies` - List all 8 semantic policies
- `POST /api/v1/semantic/validate` - Run LLM-powered validation on a contract
- `GET /api/v1/semantic/models` - List models available in Ollama
- `POST /api/v1/semantic/models/pull/{model}` - Pull a new Ollama model

#### Policy Orchestration

- `POST /api/v1/orchestration/analyze` - Get risk assessment and recommended strategy
- `POST /api/v1/orchestration/validate` - Validate with explicit strategy (fast/balanced/thorough/adaptive)
- `POST /api/v1/orchestration/recommend-strategy` - Get strategy recommendation with reasoning
- `GET /api/v1/orchestration/strategies` - List available strategies with descriptions
- `GET /api/v1/orchestration/stats` - Engine status and performance statistics

#### System

- `GET /` - API information (name, version, docs URL)
- `GET /health` - Health check (`{"status": "healthy"}`)

## ğŸ­ Demo Scenario

The platform includes a realistic financial services demo with intentional policy violations.

### Demo Tables

1. **customer_accounts** (10 records)
   - Contains PII (email, SSN, phone, DOB)
   - **Violations**: Missing encryption documentation, missing compliance tags

2. **transactions** (23 records)
   - Time-sensitive financial transactions
   - **Violations**: Missing freshness SLA, NULL status values, no enum constraints
   - Includes suspicious patterns (large purchases, late-night withdrawals)

3. **fraud_alerts** (6 records)
   - Critical fraud detection data
   - **Violations**: Missing quality thresholds, NULL risk scores
   - Mix of confirmed fraud, false positives, and investigating cases

### Expected Validation Report

When registering `customer_accounts`, you'll see:

```json
{
  "status": "failed",
  "passed": 8,
  "warnings": 3,
  "failures": 2,
  "violations": [
    {
      "type": "critical",
      "policy": "SD001: pii_encryption_required",
      "field": "customer_ssn, customer_email, customer_phone",
      "message": "PII fields require encryption but encryption_required is False",
      "remediation": "Set 'encryption_required: true' in governance metadata..."
    },
    {
      "type": "warning",
      "policy": "SD003: pii_compliance_tags",
      "field": "governance.compliance_tags",
      "message": "Datasets with PII should specify compliance frameworks",
      "remediation": "Add compliance tags like GDPR, CCPA, HIPAA..."
    }
  ]
}
```

## ğŸ“œ Policy Definitions

### Sensitive Data Policies (SD)

| ID | Name | Severity | Description |
|----|------|----------|-------------|
| SD001 | pii_encryption_required | Critical | All PII fields must have encryption enabled |
| SD002 | retention_policy_required | Critical | Confidential/restricted data must specify retention period |
| SD003 | pii_compliance_tags | Warning | PII datasets should specify compliance frameworks |
| SD004 | restricted_use_cases | Critical | Restricted data must specify approved use cases |
| SD005 | cross_border_pii | Critical | Cross-border PII requires data residency specification |

### Data Quality Policies (DQ)

| ID | Name | Severity | Description |
|----|------|----------|-------------|
| DQ001 | critical_data_completeness | Critical | Confidential/restricted data requires â‰¥95% completeness |
| DQ002 | freshness_sla_required | Warning | Temporal datasets should specify freshness SLA |
| DQ003 | uniqueness_specification | Warning | Key fields should have uniqueness constraints |
| DQ004 | accuracy_threshold_alignment | Warning | Accuracy thresholds should align with classification |
| DQ005 | quality_tier_definition | Warning | Datasets should define a quality tier (Gold/Silver/Bronze) |

### Schema Governance Policies (SG)

| ID | Name | Severity | Description |
|----|------|----------|-------------|
| SG001 | field_documentation_required | Warning | All fields should have descriptions |
| SG002 | required_field_consistency | Critical | Required fields cannot be nullable |
| SG003 | dataset_ownership_required | Critical | Datasets must have assigned ownership |
| SG004 | string_field_constraints | Warning | String fields should have max_length |
| SG005 | enum_value_specification | Warning | Enum fields should list valid values |
| SG006 | breaking_schema_changes | Critical | Breaking changes require major version bump |
| SG007 | versioning_strategy | Warning | Datasets should have a documented versioning strategy |

### Semantic Policies (SEM) â€” Requires Ollama

| ID | Name | Severity | Description |
|----|------|----------|-------------|
| SEM001 | sensitive_data_context_detection | Warning | Detects PII/sensitive data based on context, not just naming |
| SEM002 | business_logic_consistency | Warning | Validates governance rules make business sense |
| SEM003 | security_pattern_detection | Critical | Identifies potential security vulnerabilities in schema design |
| SEM004 | compliance_intent_verification | Warning | Verifies compliance tags actually apply to the data |
| SEM005 | data_quality_semantic_validation | Warning | Validates quality thresholds are realistic for the data type |
| SEM006 | field_relationship_analysis | Warning | Detects semantic relationships that increase sensitivity |
| SEM007 | naming_convention_analysis | Info | Analyzes naming for clarity and consistency |
| SEM008 | use_case_appropriateness | Warning | Evaluates if approved use cases fit the data classification |

## âœ¨ Feature Highlights

### Dataset Registration Wizard
- **Multi-step form** with progress indicator
- **PostgreSQL import** - automatically detect schema and PII
- **Manual entry** - define schema field by field
- **Real-time validation** - see policy violations before submission
- **Governance setup** - classification, retention, compliance tags

### Subscription Workflow
- **Self-service catalog** - browse and discover datasets
- **SLA negotiation** - define latency, availability, staleness requirements
- **Field-level access** - request only the fields you need
- **Business justification** - explain why you need the data
- **Approval tracking** - see status of your requests

### Compliance Dashboard
- **Real-time metrics** - compliance rate, violations, subscriptions
- **Trend analysis** - track improvements over time
- **Policy insights** - identify most violated policies
- **Classification breakdown** - compliance by data sensitivity
- **Interactive charts** - powered by Recharts

### Violation Management
- **Actionable alerts** - see what's wrong and how to fix it
- **Remediation guidance** - step-by-step instructions with examples
- **Policy references** - link to full policy documentation
- **Severity levels** - critical, warning, info
- **Field-specific** - know exactly which fields are problematic

### Contract Versioning
- **Semantic versioning** - MAJOR.MINOR.PATCH
- **Git integration** - full history with commit messages
- **Automatic updates** - new version on subscription approval
- **Diff comparison** - see what changed between versions
- **Audit trail** - who made changes and when

## ğŸ”§ Troubleshooting

### PostgreSQL Won't Start

```bash
# Check if port 5432 is already in use
lsof -i :5432

# Stop existing PostgreSQL if needed
docker-compose down

# Remove volumes and restart
docker-compose down -v
docker-compose up -d
```

### Backend Won't Start

```bash
# Check Python version (must be 3.10+)
python --version

# Reinstall dependencies
pip install -r backend/requirements.txt --upgrade

# Check for port conflicts
lsof -i :8000
```

### Schema Import Fails

```bash
# Verify PostgreSQL connection
docker exec -it governance_postgres psql -U governance_user -d financial_demo -c "\dt"

# You should see: customer_accounts, transactions, fraud_alerts
```

### Tests Fail

```bash
# Make sure both PostgreSQL and backend are running
docker ps  # Should show governance_postgres
curl http://localhost:8000/health  # Should return {"status": "healthy"}

# Run tests with verbose output
python test_setup.py
```

### Frontend Won't Start

```bash
# Check Node.js version (must be 18+)
node --version

# Check npm version
npm --version

# Clear node_modules and reinstall
cd frontend
rm -rf node_modules package-lock.json
npm install

# Check for port conflicts
lsof -i :5173
```

### Frontend Can't Connect to Backend

```bash
# Verify backend is running
curl http://localhost:8000/health

# Check CORS configuration in backend/app/main.py
# Should include http://localhost:5173

# Check browser console for errors
# Open DevTools (F12) â†’ Console tab
```

### Subscription Approval Fails

```bash
# Check backend logs for errors
# Look for contract versioning errors

# Verify Git is initialized
ls -la backend/contracts/.git

# Check database for subscription record
# Should have status "pending" before approval
```

### Charts Not Displaying

```bash
# Verify Recharts is installed
cd frontend
npm list recharts

# If missing, install it
npm install recharts

# Clear browser cache
# Hard reload: Ctrl+Shift+R (Windows/Linux) or Cmd+Shift+R (Mac)
```

## ğŸš€ Next Steps

### âœ… Completed Features

- âœ… Data Owner UI with dataset registration wizard
- âœ… Data Consumer UI with catalog browser and subscription form
- âœ… Data Steward UI with approval queue and contract review
- âœ… Platform Admin Dashboard with compliance metrics and trends
- âœ… Complete subscription workflow with SLA negotiation
- âœ… Automatic contract versioning on subscription approval
- âœ… Real-time violation tracking and remediation guidance
- âœ… PostgreSQL schema import with PII detection
- âœ… 17 governance policies with actionable validation

### ğŸ”œ Recommended Enhancements

#### Security & Authentication
1. **OAuth2/JWT Authentication**: Replace demo auth with proper authentication
2. **Role-Based Access Control (RBAC)**: Enforce permissions at API level
3. **Audit Logging**: Track all user actions for compliance
4. **Secret Management**: Integrate Azure Key Vault or HashiCorp Vault
5. **Data Encryption**: Encrypt PII fields at rest and in transit

#### Additional Data Sources
1. **Azure Data Lake Gen2**: Import schemas from ADLS
2. **Azure Blob Storage**: Support for CSV/Parquet files
3. **Snowflake Connector**: Schema import from Snowflake
4. **AWS S3**: Support for S3-based data lakes
5. **API Schemas**: Import from OpenAPI/Swagger definitions

#### Advanced Features
1. **Data Lineage Tracking**: Visualize data flow and transformations
2. **Real-Time Monitoring**: Alert on policy violations and SLA breaches
3. **Pre-Commit Hooks**: Prevent non-compliant contracts from being committed
4. **CI/CD Integration**: Validate contracts in deployment pipelines
5. **Notification System**: Email/Slack alerts for approvals and violations
6. **Advanced Analytics**: ML-powered PII detection, anomaly detection
7. **Contract Testing**: Automated tests for contract compatibility
8. **Data Quality Scoring**: Automated quality metrics calculation

#### User Experience
1. **Dataset Preview**: Show sample data in catalog
2. **Contract Diff Viewer**: Visual contract comparison
3. **Policy Editor**: UI for creating/editing policies
4. **Custom Dashboards**: User-configurable analytics views
5. **Export Reports**: PDF/Excel export for compliance reports
6. **Mobile App**: Mobile interface for approvals and monitoring

#### Enterprise Features
1. **Multi-Tenancy**: Support for multiple organizations
2. **SSO Integration**: Azure AD, Okta, etc.
3. **Advanced RBAC**: Fine-grained permissions
4. **Compliance Reports**: Automated SOC2, GDPR, HIPAA reports
5. **SLA Monitoring**: Real-time SLA compliance tracking
6. **Cost Tracking**: Monitor data access costs by consumer

## ğŸ“ File Structure

```
data-governance-platform/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/          # SQLAlchemy ORM models
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset.py       # Dataset (20 fields, lifecycle status)
â”‚   â”‚   â”‚   â”œâ”€â”€ contract.py      # Contract (18 fields, semantic versioning)
â”‚   â”‚   â”‚   â”œâ”€â”€ subscription.py  # Subscription (22 fields, approval workflow)
â”‚   â”‚   â”‚   â””â”€â”€ user.py          # User (11 fields, role-based access)
â”‚   â”‚   â”œâ”€â”€ schemas/         # Pydantic v2 validation schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset_schemas.py    # Dataset schemas (10+ classes)
â”‚   â”‚   â”‚   â”œâ”€â”€ contract_schemas.py   # Contract schemas (6 classes)
â”‚   â”‚   â”‚   â””â”€â”€ subscription_schemas.py # Subscription schemas (8 classes)
â”‚   â”‚   â”œâ”€â”€ api/             # FastAPI route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ datasets.py      # Dataset CRUD and schema import (7 routes)
â”‚   â”‚   â”‚   â”œâ”€â”€ subscriptions.py # Subscription workflow (6 routes)
â”‚   â”‚   â”‚   â”œâ”€â”€ git.py           # Git operations (5 routes)
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic.py      # LLM-powered validation (5 routes)
â”‚   â”‚   â”‚   â””â”€â”€ orchestration.py # Intelligent routing (5 routes)
â”‚   â”‚   â”œâ”€â”€ services/        # Business logic layer
â”‚   â”‚   â”‚   â”œâ”€â”€ policy_engine.py         # 17 YAML-based governance policies
â”‚   â”‚   â”‚   â”œâ”€â”€ contract_service.py      # Contract generation, versioning, diffs
â”‚   â”‚   â”‚   â”œâ”€â”€ postgres_connector.py    # Schema import with PII detection
â”‚   â”‚   â”‚   â”œâ”€â”€ git_service.py           # Git version control and audit trail
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_policy_engine.py # 8 LLM-powered semantic policies
â”‚   â”‚   â”‚   â”œâ”€â”€ policy_orchestrator.py   # FAST/BALANCED/THOROUGH/ADAPTIVE routing
â”‚   â”‚   â”‚   â””â”€â”€ ollama_client.py         # Local Ollama LLM client
â”‚   â”‚   â”œâ”€â”€ config.py        # Pydantic Settings configuration
â”‚   â”‚   â”œâ”€â”€ database.py      # SQLAlchemy setup (SQLite metadata DB)
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI application entry point
â”‚   â”œâ”€â”€ policies/            # YAML policy definitions
â”‚   â”‚   â”œâ”€â”€ sensitive_data_policies.yaml     # SD001-SD005 (5 policies)
â”‚   â”‚   â”œâ”€â”€ data_quality_policies.yaml       # DQ001-DQ005 (5 policies)
â”‚   â”‚   â”œâ”€â”€ schema_governance_policies.yaml  # SG001-SG007 (7 policies)
â”‚   â”‚   â””â”€â”€ semantic_policies.yaml           # SEM001-SEM008 (8 semantic policies)
â”‚   â”œâ”€â”€ contracts/           # Git repository for versioned contracts
â”‚   â”œâ”€â”€ tests/               # Comprehensive pytest test suite (101 tests)
â”‚   â”‚   â”œâ”€â”€ conftest.py              # Fixtures and configuration
â”‚   â”‚   â”œâ”€â”€ test_policy_engine.py    # 17 policy validation tests (all passing)
â”‚   â”‚   â”œâ”€â”€ test_contract_service.py # Contract generation tests
â”‚   â”‚   â”œâ”€â”€ test_api_datasets.py     # Dataset API tests (21 tests)
â”‚   â”‚   â”œâ”€â”€ test_api_subscriptions.py # Subscription workflow tests (14 tests)
â”‚   â”‚   â”œâ”€â”€ test_api_git.py          # Git API tests (14 tests, all passing)
â”‚   â”‚   â”œâ”€â”€ test_models.py           # Database model tests (13 tests)
â”‚   â”‚   â”œâ”€â”€ test_semantic_scanner.py # Semantic policy tests
â”‚   â”‚   â””â”€â”€ test_orchestration.py    # Policy orchestration tests
â”‚   â”œâ”€â”€ pytest.ini           # Pytest configuration and markers
â”‚   â””â”€â”€ requirements.txt     # Python dependencies (15+ packages)
â”œâ”€â”€ frontend/                # React 18 + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ Layout.jsx       # App layout with role-based navigation
â”‚   â”‚   â”œâ”€â”€ contexts/
â”‚   â”‚   â”‚   â””â”€â”€ AuthContext.jsx  # Role-based auth context (Zustand)
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ RoleSelector.jsx                          # Role selection entry
â”‚   â”‚   â”‚   â”œâ”€â”€ DataOwner/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DatasetRegistrationWizard.jsx         # 4-step registration wizard
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ OwnerDashboard.jsx                    # Owned datasets + violations
â”‚   â”‚   â”‚   â”œâ”€â”€ DataConsumer/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DataCatalogBrowser.jsx                # Catalog + subscription request
â”‚   â”‚   â”‚   â”œâ”€â”€ DataSteward/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ApprovalQueue.jsx                     # Subscription approval workflow
â”‚   â”‚   â”‚   â””â”€â”€ Admin/
â”‚   â”‚   â”‚       â””â”€â”€ ComplianceDashboard.jsx               # Compliance metrics + Recharts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js           # Axios API client (datasets, subscriptions, git)
â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”‚   â””â”€â”€ index.js         # Zustand state management (5 stores)
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ setup.js         # Vitest test setup
â”‚   â”‚   â”‚   â””â”€â”€ api.test.js      # API service tests
â”‚   â”‚   â”œâ”€â”€ App.jsx              # React Router configuration
â”‚   â”‚   â””â”€â”€ main.jsx             # React entry point
â”‚   â”œâ”€â”€ package.json         # NPM dependencies (15 packages)
â”‚   â”œâ”€â”€ vite.config.js       # Vite build configuration (API proxy)
â”‚   â””â”€â”€ vitest.config.js     # Frontend test configuration
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ setup_postgres.sql   # PostgreSQL schema (3 tables)
â”‚   â””â”€â”€ sample_data.sql      # 39 records with intentional violations
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ register_customer_accounts.json  # Example dataset registration payload
â”œâ”€â”€ docker-compose.yml       # PostgreSQL 15 demo setup
â”œâ”€â”€ test_setup.py            # Automated 5-test setup verification suite
â”œâ”€â”€ start.sh                 # Quick backend start script
â””â”€â”€ README.md                # This file
```

## ğŸ¤ Contributing

This is a demonstration platform. For production use:

1. Add authentication (OAuth2/JWT)
2. Encrypt sensitive data (SSN, passwords)
3. Use proper secret management (Azure Key Vault)
4. Add comprehensive error handling
5. Implement audit logging
6. Add rate limiting
7. Use production-grade database (PostgreSQL/Azure SQL)

## ğŸ“„ License

This is a demonstration project for educational purposes.

## ğŸ“ Key Takeaways

1. **Prevention Over Detection**: Validate at contract creation, not production
2. **Federated Governance**: Autonomy with centralized standards (UN Peacekeeping)
3. **Policy-as-Code**: Version-controlled, testable governance rules
4. **Developer-Friendly**: Clear error messages with actionable remediation
5. **Git Integration**: Full audit trail and diff capabilities
6. **Dual Contracts**: Human-readable for understanding, machine-readable for automation
7. **Role-Based UIs**: Dedicated interfaces for owners, consumers, stewards, and admins
8. **End-to-End Workflows**: Complete subscription lifecycle with automatic contract versioning
9. **Real-Time Analytics**: Live compliance metrics and violation trends
10. **Self-Service**: Empowers data consumers to discover and request access independently

---

**Built with â¤ï¸ for Data Governance**
